{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `analysis.py` module contains the dataset and log likelihood function which given a model instance (set up by\n",
        "the non-linear search) fits the dataset and returns the log likelihood of that model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "class Analysis(af.Analysis):\n",
        "\n",
        "    \"\"\"\n",
        "    In this example the Analysis only contains the data and noise-map. It can be easily extended however, for more\n",
        "    complex data-sets and model fitting problems.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, noise_map):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.noise_map = noise_map\n",
        "\n",
        "    \"\"\"\n",
        "    In the log_likelihood_function function below, `instance` is an instance of our model, which in this example is\n",
        "    an instance of the `Gaussian` class and Exponential class in `model.py`. Their parameters are set via the\n",
        "    non-linear search. This gives us the instance of the model we need to fit our data!\n",
        "    \"\"\"\n",
        "\n",
        "    def log_likelihood_function(self, instance):\n",
        "        \"\"\"\n",
        "        Determine the log likelihood of a fit of multiple profiles to the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        instance : af.Collection\n",
        "            The model instances of the profiles.\n",
        "\n",
        "        Returnsn\n",
        "        -------\n",
        "        fit : Fit.log_likelihood\n",
        "            The log likelihood value indicating how well this model fit the dataset.\n",
        "\n",
        "        The `instance` that comes into this method is a Collection. It contains instances of every class\n",
        "        we instantiated it with, where each instance is named following the names given to the Collection,\n",
        "        which in this example is a `Gaussian` (with name `gaussian) and Exponential (with name `exponential`):\n",
        "        \"\"\"\n",
        "        # print(\"Gaussian Instance:\")\n",
        "        # print(\"Centre = \", instance.gaussian.centre)\n",
        "        # print(\"Intensity = \", instance.gaussian.intensity)\n",
        "        # print(\"Sigma = \", instance.gaussian.sigma)\n",
        "\n",
        "        # print(\"Exponential Instance:\")\n",
        "        # print(\"Centre = \", instance.exponential.centre)\n",
        "        # print(\"Intensity = \", instance.exponential.intensity)\n",
        "        # print(\"Rate = \", instance.exponential.rate)\n",
        "\n",
        "        \"\"\"Get the range of x-values the data is defined on, to evaluate the model of the profiles.\"\"\"\n",
        "\n",
        "        xvalues = np.arange(self.data.shape[0])\n",
        "\n",
        "        \"\"\"\n",
        "        The simplest way to create the summed profile is to add the profile of each model component. If we\n",
        "        know we are going to fit a `Gaussian` + Exponential we can do the following:\n",
        "\n",
        "            model_data_gaussian = instance.gaussian.profile_from_xvalues(xvalues=xvalues)\n",
        "            model_data_exponential = instance.exponential.profile_from_xvalues(xvalues=xvalues)\n",
        "            model_data = model_data_gaussian + model_data_exponential\n",
        "\n",
        "        However, this does not work if we change our model components. However, the *instance* variable is a list of\n",
        "        our model components. We can iterate over this list, calling their profile_from_xvalues and summing the result\n",
        "        to compute the summed profile of any model.\n",
        "        \n",
        "        Use these xvalues to create model data of our profiles.\n",
        "        \n",
        "        \"\"\"\n",
        "        model_data = sum(\n",
        "            [line.profile_from_xvalues(xvalues=xvalues) for line in instance]\n",
        "        )\n",
        "\n",
        "        \"\"\"Fit the model profile data to the observed data, computing the residuals and chi-squareds.\"\"\"\n",
        "        residual_map = self.data - model_data\n",
        "        chi_squared_map = (residual_map / self.noise_map) ** 2.0\n",
        "        log_likelihood = -0.5 * sum(chi_squared_map)\n",
        "\n",
        "        return log_likelihood\n",
        "\n",
        "    def visualize(self, paths, instance, during_analysis):\n",
        "\n",
        "        \"\"\"\n",
        "        During a model-fit, the `visualize` method is called throughout the non-linear search. The `instance` passed\n",
        "        into the visualize method is maximum log likelihood solution obtained by the model-fit so far and it can be\n",
        "        used to provide on-the-fly images showing how the model-fit is going.\n",
        "        \"\"\"\n",
        "\n",
        "        xvalues = np.arange(self.data.shape[0])\n",
        "\n",
        "        model_datas = [line.profile_from_xvalues(xvalues=xvalues) for line in instance]\n",
        "        model_data = sum(model_datas)\n",
        "\n",
        "        plt.errorbar(\n",
        "            x=xvalues,\n",
        "            y=self.data,\n",
        "            yerr=self.noise_map,\n",
        "            color=\"k\",\n",
        "            ecolor=\"k\",\n",
        "            elinewidth=1,\n",
        "            capsize=2,\n",
        "        )\n",
        "        plt.plot(range(self.data.shape[0]), model_data, color=\"r\")\n",
        "        for model_data_individual in model_datas:\n",
        "            plt.plot(range(self.data.shape[0]), model_data_individual, \"--\")\n",
        "        plt.title(\"Dynesty model fit to 1D Gaussian + Exponential dataset.\")\n",
        "        plt.xlabel(\"x values of profile\")\n",
        "        plt.ylabel(\"Profile intensity\")\n",
        "\n",
        "        os.makedirs(paths.image_path, exist_ok=True)\n",
        "        plt.savefig(path.join(paths.image_path, \"model_fit.png\"))\n",
        "        plt.clf()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}