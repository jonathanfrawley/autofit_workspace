{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example: Fit__\n",
    "\n",
    "In this example, we'll fit 1D data of a `Gaussian` profile with a 1D `Gaussian` model using the non-linear searches\n",
    "emcee, Dynesty and PySwarms.\n",
    "\n",
    "If you haven't already, you should checkout the files `example/model.py` and `example/analysis.py` to see how we have\n",
    "provided PyAutoFit with the necessary information on our model, data and log likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import autofit as af\n",
    "import model as m\n",
    "import analysis as a\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data__\n",
    "\n",
    "First, lets load data of a 1D Gaussian, by loading it from a .json file in the directory \n",
    "`autofit_workspace/dataset//gaussian_x1`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset_path = path.join(\"dataset\", \"example_1d\", \"gaussian_x1\")\n",
    "data = af.util.numpy_array_from_json(file_path=path.join(dataset_path, \"data.json\"))\n",
    "noise_map = af.util.numpy_array_from_json(\n",
    "    file_path=path.join(dataset_path, \"noise_map.json\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the data, including its error bars. We'll use its shape to determine the xvalues of the\n",
    "data for the plot."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "xvalues = range(data.shape[0])\n",
    "\n",
    "plt.errorbar(\n",
    "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model__\n",
    "\n",
    "Next, we create our model, which in this case corresponds to a single Gaussian. In model.py, you will have noted\n",
    "this `Gaussian` has 3 parameters (centre, intensity and sigma). These are the free parameters of our model that the\n",
    "non-linear search fits for, meaning the non-linear parameter space has dimensionality = 3."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = af.Model(m.Gaussian)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout `autofit_workspace/config/priors/model.json`, this config file defines the default priors of the `Gaussian` \n",
    "model component. \n",
    "\n",
    "We can overwrite priors before running the `NonLinearSearch` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.centre = af.UniformPrior(lower_limit=0.0, upper_limit=100.0)\n",
    "model.intensity = af.LogUniformPrior(lower_limit=1e-2, upper_limit=1e2)\n",
    "model.sigma = af.GaussianPrior(\n",
    "    mean=10.0, sigma=5.0, lower_limit=0.0, upper_limit=np.inf\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Analysis__\n",
    "\n",
    "We now set up our Analysis, using the class described in `analysis.py`. The analysis describes how given an instance\n",
    "of our model (a Gaussian) we fit the data and return a log likelihood value. For this simple example, we only have to\n",
    "pass it the data and its noise-map."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis = a.Analysis(data=data, noise_map=noise_map)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "__Paths__\n",
    "\n",
    "We specify a `path_prefix` which is passed to the non-linear search below, so that our results go to the\n",
    "folder `autofit_workspace/output/overview/simple`. The search is also given a `name`, which defines the folder\n",
    "results are output too.\n",
    "\n",
    "Results are output to a folder which is a collection of random characters, which is the 'unique_identifier' of\n",
    "the model-fit. This identifier is generated based on the model fitted and search used, such that an identical\n",
    "combination of model and search generates the same identifier.\n",
    "\n",
    "This ensures that rerunning an identical fit will use the existing results to resume the model-fit. In contrast, if\n",
    "you change the model or search, a new unique identifier will be generated, ensuring that the model-fit results are\n",
    "output into a separate folder."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_prefix = path.join(\"overview\", \"simple\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################\n",
    "###### NESTED SAMPLING ######\n",
    "#############################\n",
    "\n",
    "We finally choose and set up our non-linear search. we'll first fit the data with the nested sampling algorithm\n",
    "Dynesty. Below, we manually specify all of the Dynesty settings, however if we omitted them the default values\n",
    "found in the config file `config/non_linear/Dynesty.ini` would be used.\n",
    "\n",
    "We also specify a `path_prefix`, so that our results go to the folder `autofit_workspace/output/overview/simple`.\n",
    "\n",
    "For a full description of Dynesty checkout its Github and documentation webpages:\n",
    "\n",
    "https://github.com/joshspeagle/dynesty\n",
    "https://dynesty.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dynesty = af.DynestyStatic(\n",
    "    path_prefix=path_prefix,\n",
    "    name=\"DynestyStatic\",\n",
    "    nlive=100,\n",
    "    bound=\"multi\",\n",
    "    sample=\"auto\",\n",
    "    bootstrap=None,\n",
    "    enlarge=None,\n",
    "    update_interval=None,\n",
    "    vol_dec=0.5,\n",
    "    vol_check=2.0,\n",
    "    walks=25,\n",
    "    facc=0.5,\n",
    "    slices=5,\n",
    "    fmove=0.9,\n",
    "    max_move=100,\n",
    "    iterations_per_update=500,\n",
    "    number_of_cores=1,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the fit with Dynesty, we pass it our model and analysis and we`re good to go!\n",
    "\n",
    "Checkout the folder `autofit_workspace/output/dynestystatic`, where the `NonLinearSearch` results, visualization and\n",
    "information can be found."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "result = dynesty.fit(model=model, analysis=analysis)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result__\n",
    "\n",
    "The result object returned by the fit provides information on the results of the non-linear search. Lets use it to\n",
    "compare the maximum log likelihood `Gaussian` to the data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_data = result.max_log_likelihood_instance.profile_from_xvalues(\n",
    "    xvalues=np.arange(data.shape[0])\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
    ")\n",
    "plt.plot(xvalues, model_data, color=\"r\")\n",
    "plt.title(\"Dynesty model fit to 1D Gaussian dataset.\")\n",
    "plt.xlabel(\"x values of profile\")\n",
    "plt.ylabel(\"Profile intensity\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discuss in more detail how to use a results object in the files `autofit_workspace/example/simple/result.py`.\n",
    "\n",
    "##################\n",
    "###### MCMC ######\n",
    "##################\n",
    "\n",
    "To use a different non-linear we simply use call a different search from PyAutoFit, passing it the same the model\n",
    "and analysis as we did before to perform the fit. Below, we fit the same dataset using the MCMC sampler Emcee.\n",
    "Again, we manually specify all of the Emcee settings, however if they were omitted the values found in the config\n",
    "file `config/non_linear/Emcee.ini` would be used instead.\n",
    "\n",
    "For a full description of Emcee, checkout its Github and readthedocs webpages:\n",
    "\n",
    "https://github.com/dfm/emcee\n",
    "https://emcee.readthedocs.io/en/stable/\n",
    "\n",
    "**PyAutoFit** extends **emcee** by providing an option to check the auto-correlation length of the samples\n",
    "during the run and terminating sampling early if these meet a specified threshold. See this page\n",
    "(https://emcee.readthedocs.io/en/stable/tutorials/autocorr/#autocorr) for a description of how this is implemented."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "emcee = af.Emcee(\n",
    "    path_prefix=path_prefix,\n",
    "    name=\"Emcee\",\n",
    "    nwalkers=30,\n",
    "    nsteps=1000,\n",
    "    initializer=af.InitializerBall(lower_limit=0.49, upper_limit=0.51),\n",
    "    auto_correlations_settings=af.AutoCorrelationsSettings(\n",
    "        check_for_convergence=True,\n",
    "        check_size=100,\n",
    "        required_length=50,\n",
    "        change_threshold=0.01,\n",
    "    ),\n",
    "    iterations_per_update=500,\n",
    "    number_of_cores=1,\n",
    ")\n",
    "result = emcee.fit(model=model, analysis=analysis)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result__\n",
    "\n",
    "The result object returned by Emcee`s fit is similar in structure to the Dynesty result above - it again provides\n",
    "us with the maximum log likelihood instance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_data = result.max_log_likelihood_instance.profile_from_xvalues(\n",
    "    xvalues=np.arange(data.shape[0])\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
    ")\n",
    "plt.plot(xvalues, model_data, color=\"r\")\n",
    "plt.title(\"Emcee model fit to 1D Gaussian dataset.\")\n",
    "plt.xlabel(\"x values of profile\")\n",
    "plt.ylabel(\"Profile intensity\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################\n",
    "###### PARTICLE SWARM ######\n",
    "############################\n",
    "\n",
    "PyAutoFit also supports a number of searches, which seem to find the global (or local) maxima likelihood solution.\n",
    "Unlike nested samplers and MCMC algorithms, they do not extensive map out parameter space. This means they can find the\n",
    "best solution a lot faster than these algorithms, but they do not properly quantify the errors on each parameter.\n",
    "\n",
    "we'll use the Particle Swarm Optimization algorithm PySwarms. For a full description of PySwarms, checkout its Github \n",
    "and readthedocs webpages:\n",
    "\n",
    "https://github.com/ljvmiranda921/pyswarms\n",
    "https://pyswarms.readthedocs.io/en/latest/index.html\n",
    "\n",
    "**PyAutoFit** extends *PySwarms* by allowing runs to be terminated and resumed from the point of termination, as well\n",
    "as providing different options for the initial distribution of particles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pso = af.PySwarmsGlobal(\n",
    "    path_prefix=path.join(\"overview\", \"simple\"),\n",
    "    name=\"PySwarmsGlobal\",\n",
    "    n_particles=50,\n",
    "    iters=100,\n",
    "    cognitive=0.5,\n",
    "    social=0.3,\n",
    "    inertia=0.9,\n",
    "    ftol=-np.inf,\n",
    "    initializer=af.InitializerPrior(),\n",
    "    number_of_cores=1,\n",
    ")\n",
    "result = pso.fit(model=model, analysis=analysis)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result__\n",
    "\n",
    "The result object returned by PSO is again very similar in structure to previous results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_data = result.max_log_likelihood_instance.profile_from_xvalues(\n",
    "    xvalues=np.arange(data.shape[0])\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    x=xvalues, y=data, yerr=noise_map, color=\"k\", ecolor=\"k\", elinewidth=1, capsize=2\n",
    ")\n",
    "plt.plot(xvalues, model_data, color=\"r\")\n",
    "plt.title(\"PySwarms model fit to 1D Gaussian dataset.\")\n",
    "plt.xlabel(\"x values of profile\")\n",
    "plt.ylabel(\"Profile intensity\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Other Samplers__\n",
    "\n",
    "Checkout https://pyautofit.readthedocs.io/en/latest/api/api.html for the non-linear searches available in PyAutoFit."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}